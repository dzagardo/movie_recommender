{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0PFof62hYSn"
      },
      "outputs": [],
      "source": [
        "# The below codes are heavily inspired by Surprise official documentation\n",
        "# https://github.com/NicolasHug/Surprise/tree/9a263a85decc4236919b4f8a706783d7e8fcad24/surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixhJb-AwiW38"
      },
      "outputs": [],
      "source": [
        "#Dependencies : \n",
        "# Original data : User+Movie+rating\n",
        "# Environmemnt with working python libraries\n",
        "\n",
        "#Outputs of the codes\n",
        "# Dictionary Files for userIDs and MovieIDs\n",
        "# Processed Data file\n",
        "# Train/Test Data Files\n",
        "# Model Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTSoutBNnEm2"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-PPa2PmwZ8z",
        "outputId": "8aeb086e-a3bb-4467-d41a-4bb5200a42a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.7.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1633997 sha256=722c0cfdd9ec51a4ef2a487895d19e973ff0dcc2a64d37e7c6809320b9852b2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.1\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sPbKt-fTODa",
        "outputId": "8c98000a-2fce-4d91-cd40-86bccc3bbee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OxZs5vwjh81"
      },
      "outputs": [],
      "source": [
        "# DataPreProcessing.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def DataPreProcessing(file_path=\"/content/drive/MyDrive/Collab Codes/MLIP/kafka_ratings.txt\",save_as=\"/content/drive/MyDrive/Collab Codes/MLIP/preprocessed.csv\"):\n",
        "  df=pd.read_csv(\"/content/drive/MyDrive/Collab Codes/MLIP/kafka_ratings.txt\",header=None)\n",
        "  \n",
        "  df.columns=[\"Timestamp\",\"UserID\",\"Log\"]\n",
        "\n",
        "  df[\"MovieName=Rating\"]=df[\"Log\"].apply(lambda x: x.split(\"/\")[2])\n",
        "  df[\"MovieName\"]=df[\"MovieName=Rating\"].apply(lambda x: x.split(\"=\")[0])\n",
        "  df[\"rating\"]=df[\"MovieName=Rating\"].apply(lambda x: x.split(\"=\")[1])\n",
        "  \n",
        "  Data=df[[\"UserID\",\"MovieName\",\"rating\",\"Timestamp\"]]\n",
        "  \n",
        "  \n",
        "  # Data sort on timestamp\n",
        "\n",
        "  # Few duplicates of user-> movie were dropped, the lateset was picked\n",
        "  Data=Data.drop_duplicates(subset=['UserID', 'MovieName'],keep=\"last\")\n",
        "  print(\"Data.shape\",Data.shape)\n",
        "  \n",
        "  #Exception handling for data save\n",
        "  try : \n",
        "    Data.to_csv(save_as)\n",
        "    print(\"Saved at: \",save_as)\n",
        "    return True\n",
        "  except:\n",
        "    print(\"Unable to save at: \",save_as)\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqzMfD8Jll0B"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import json\n",
        "\n",
        "def make_Dictionaries(processed_data_file=\"/content/drive/MyDrive/Collab Codes/MLIP/preprocessed.csv\",dictionary_storage_location=\"/content/drive/MyDrive/Collab Codes/MLIP/\"):\n",
        "  Data=pd.read_csv(processed_data_file)\n",
        "\n",
        "    \n",
        "  # Function to return a default\n",
        "  # values for keys that is not\n",
        "  # present\n",
        "  def def_value():\n",
        "      return \"Not Present\"\n",
        "        \n",
        "  # Defining the dict\n",
        "  iid_dict = defaultdict(def_value)\n",
        "  uid_dict = defaultdict(def_value)\n",
        "  sort_movies=Data['MovieName'].unique()\n",
        "  sort_movies.sort()\n",
        "  for i in range(len(sort_movies)):\n",
        "    iid_dict[sort_movies[i]]=i\n",
        "\n",
        "  sort_users=Data['UserID'].unique()\n",
        "  sort_users.sort()\n",
        "  for i in range(len(sort_users)):\n",
        "    uid_dict[int(sort_users[i])]=i\n",
        "\n",
        "  with open(dictionary_storage_location+\"iid_dict.json\", \"w\") as outfile:\n",
        "    json.dump(iid_dict, outfile)\n",
        "  with open(dictionary_storage_location+\"uid_dict.json\", \"w\") as outfile:\n",
        "    json.dump(uid_dict, outfile)\n",
        "\n",
        "  return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huMJtFdHsIhf"
      },
      "outputs": [],
      "source": [
        "# importing the module\n",
        "import json\n",
        " \n",
        "def DataRemapping(processed_data_file=\"/content/drive/MyDrive/Collab Codes/MLIP/preprocessed.csv\",dictionary_storage_location=\"/content/drive/MyDrive/Collab Codes/MLIP/\"):\n",
        "  # Opening JSON file\n",
        "  with open(dictionary_storage_location+'iid_dict.json') as json_file:\n",
        "      iid_dict = json.load(json_file)\n",
        "  with open(dictionary_storage_location+'uid_dict.json') as json_file:\n",
        "      uid_dict = json.load(json_file)\n",
        "  def def_value():\n",
        "      return \"Not Present\"\n",
        "        \n",
        "  # Defining the dict\n",
        "  iid_dict = defaultdict(int,iid_dict)\n",
        "  uid_dict = defaultdict(int,uid_dict)\n",
        "  \n",
        "  Data=pd.read_csv(processed_data_file)\n",
        "  Data['item']=Data['MovieName'].apply(lambda x: iid_dict[x])\n",
        "  Data['user']=Data['UserID'].apply(lambda x: uid_dict[str(x)])\n",
        "  # print(Data.head())\n",
        "  Data_selected=Data[['user','item','rating']]\n",
        "  # print(Data_selected.head())\n",
        "  Data_selected.to_csv(dictionary_storage_location+\"RemappedData.csv\")\n",
        "  \n",
        "  User_watched_movies=Data_selected.groupby('user')['item'].apply(list)\n",
        "  User_watched_movies=dict(User_watched_movies)\n",
        "  with open(dictionary_storage_location+\"Users_Watched_Movies.json\", \"w\") as outfile:\n",
        "    json.dump(User_watched_movies, outfile)\n",
        "  \n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV6OW8RC_XjF"
      },
      "outputs": [],
      "source": [
        "from surprise import Reader\n",
        "from surprise import NMF\n",
        "from surprise import Dataset\n",
        "import pandas as pd\n",
        "from surprise.accuracy import rmse\n",
        "from surprise.model_selection import KFold\n",
        "import numpy as np\n",
        "def train_nmf(processed_data_file=\"/content/drive/MyDrive/Collab Codes/MLIP/RemappedData.csv\"):\n",
        "  \n",
        "  Data_selected=pd.read_csv(processed_data_file)\n",
        "\n",
        "  reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "  # Loads Pandas dataframe\n",
        "  data = Dataset.load_from_df(Data_selected[[\"user\", \"item\", \"rating\"]], reader)\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  lr_all is the learning rate for all parameters (how much the parameters are adjusted in each iteration)\n",
        "  reg_all is the regularization term for all parameters, which is a penalty term added to prevent overfitting.\n",
        "  \"\"\"\n",
        "\n",
        "  param_grid = {\n",
        "      \"n_epochs\": [5, 10],\n",
        "      \"lr_all\": [0.002, 0.005],\n",
        "      \"reg_all\": [0.4, 0.6]\n",
        "  }\n",
        "\n",
        "  # Get the best params using GridSearchCV\n",
        "  # gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3)\n",
        "  # gs.fit(data)\n",
        "  # Post GS we have the below params\n",
        "  # best_params=best_params = gs.best_params[\"rmse\"]\n",
        "  best_params={'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
        "  # print(\"BEST PARAM:\",best_params)\n",
        "  # Extract and train model with best params\n",
        "  svd_algo = NMF()\n",
        "  # Train\n",
        "  trainingSet = data.build_full_trainset()\n",
        "\n",
        "\n",
        "  svd_algo.fit(trainingSet)\n",
        "\n",
        "  kf = KFold(n_splits=3)\n",
        "  errors=[]\n",
        "  for trainset, testset in kf.split(data):\n",
        "    svd_algo.fit(trainset)                             \n",
        "    predictions = svd_algo.test(testset)\n",
        "    errors.append(rmse(predictions))\n",
        "\n",
        "  return svd_algo,np.mean(errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czKwV26Vv4VB"
      },
      "outputs": [],
      "source": [
        "from surprise import Reader\n",
        "from surprise import SVDpp\n",
        "from surprise import Dataset\n",
        "import pandas as pd\n",
        "from surprise.accuracy import rmse\n",
        "from surprise.model_selection import KFold\n",
        "import numpy as np\n",
        "def train_svdpp(processed_data_file=\"/content/drive/MyDrive/Collab Codes/MLIP/RemappedData.csv\"):\n",
        "  \n",
        "  Data_selected=pd.read_csv(processed_data_file)\n",
        "\n",
        "  reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "  # Loads Pandas dataframe\n",
        "  data = Dataset.load_from_df(Data_selected[[\"user\", \"item\", \"rating\"]], reader)\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  lr_all is the learning rate for all parameters (how much the parameters are adjusted in each iteration)\n",
        "  reg_all is the regularization term for all parameters, which is a penalty term added to prevent overfitting.\n",
        "  \"\"\"\n",
        "\n",
        "  param_grid = {\n",
        "      \"n_epochs\": [5, 10],\n",
        "      \"lr_all\": [0.002, 0.005],\n",
        "      \"reg_all\": [0.4, 0.6]\n",
        "  }\n",
        "\n",
        "  # Get the best params using GridSearchCV\n",
        "  # gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3)\n",
        "  # gs.fit(data)\n",
        "  # Post GS we have the below params\n",
        "  # best_params=best_params = gs.best_params[\"rmse\"]\n",
        "  best_params={'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
        "  # print(\"BEST PARAM:\",best_params)\n",
        "  # Extract and train model with best params\n",
        "  svd_algo = SVDpp()\n",
        "  # Train\n",
        "  trainingSet = data.build_full_trainset()\n",
        "\n",
        "\n",
        "  svd_algo.fit(trainingSet)\n",
        "\n",
        "  kf = KFold(n_splits=3)\n",
        "  errors=[]\n",
        "  for trainset, testset in kf.split(data):\n",
        "    svd_algo.fit(trainset)                             \n",
        "    predictions = svd_algo.test(testset)\n",
        "    errors.append(rmse(predictions))\n",
        "\n",
        "  return svd_algo,np.mean(errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhRsdxw2w2rc"
      },
      "outputs": [],
      "source": [
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "import pandas as pd\n",
        "from surprise import SVD\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from surprise.accuracy import rmse\n",
        "from surprise.model_selection import KFold\n",
        "\n",
        "\n",
        "def train_SVD_wGridSearch(processed_data_file=\"/content/drive/MyDrive/Collab Codes/MLIP/RemappedData.csv\"):\n",
        "  \n",
        "  Data_selected=pd.read_csv(processed_data_file)\n",
        "\n",
        "  reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "  # Loads Pandas dataframe\n",
        "  data = Dataset.load_from_df(Data_selected[[\"user\", \"item\", \"rating\"]], reader)\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  lr_all is the learning rate for all parameters (how much the parameters are adjusted in each iteration)\n",
        "  reg_all is the regularization term for all parameters, which is a penalty term added to prevent overfitting.\n",
        "  \"\"\"\n",
        "\n",
        "  param_grid = {\n",
        "      \"n_epochs\": [5, 10],\n",
        "      \"lr_all\": [0.002, 0.005],\n",
        "      \"reg_all\": [0.4, 0.6]\n",
        "  }\n",
        "\n",
        "  # Get the best params using GridSearchCV\n",
        "  # gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3)\n",
        "  # gs.fit(data)\n",
        "  # Post GS we have the below params\n",
        "  # best_params=best_params = gs.best_params[\"rmse\"]\n",
        "  best_params={'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
        "  # print(\"BEST PARAM:\",best_params)\n",
        "  # Extract and train model with best params\n",
        "  svd_algo = SVD(n_epochs=best_params['n_epochs'],\n",
        "                lr_all=best_params['lr_all'],\n",
        "                reg_all=best_params['reg_all'])\n",
        "  # Train\n",
        "  trainingSet = data.build_full_trainset()\n",
        "\n",
        "\n",
        "  svd_algo.fit(trainingSet)\n",
        "\n",
        "  kf = KFold(n_splits=3)\n",
        "  errors=[]\n",
        "  for trainset, testset in kf.split(data):\n",
        "    svd_algo.fit(trainset)                             \n",
        "    predictions = svd_algo.test(testset)\n",
        "    errors.append(rmse(predictions))\n",
        "\n",
        "  return svd_algo,np.mean(errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5PjVyYLxqKo"
      },
      "outputs": [],
      "source": [
        "# the predict function for any algorithm\n",
        "def predict(algo,uid,iid,r=4):\n",
        "  ret=algo.predict(int(uid),int(iid),r)\n",
        "  # print(ret)\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If_voliin9SC"
      },
      "outputs": [],
      "source": [
        "# storing and retreiving model objects\n",
        "\n",
        "import pickle \n",
        "\n",
        "def store_model_into_pickle(algo,algo_name,dest_location=\"/content/drive/MyDrive/Collab Codes/MLIP/\"):\n",
        "  file1 = open(dest_location+algo_name+\".pickle\", \"wb\")\n",
        "  pickle.dump(algo, file1)\n",
        "  file1.close()\n",
        "  print(algo_name+\" Stored at/as :\"+dest_location+algo_name+\".pickle\")\n",
        "  return True\n",
        "  \n",
        "def get_model_from_pickle(algo_name,file_location=\"/content/drive/MyDrive/Collab Codes/MLIP/\"):\n",
        "  file_to_read = open(file_location+algo_name+\".pickle\", \"rb\")\n",
        "  loaded_object = pickle.load(file_to_read)\n",
        "  file_to_read.close()\n",
        "  print(\"returned model object\")\n",
        "  return loaded_object\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDlrdP27LMvl"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "def recommend_top_20_modviesForUser(algo_name,og_user,dictionary_storage_location=\"/content/drive/MyDrive/Collab Codes/MLIP/\"):\n",
        "  og_user=str(og_user)\n",
        "  algo=get_model_from_pickle(algo_name=algo_name)\n",
        "  with open(dictionary_storage_location+'iid_dict.json') as json_file:\n",
        "      iid_dict = json.load(json_file)\n",
        "  with open(dictionary_storage_location+'uid_dict.json') as json_file:\n",
        "      uid_dict = json.load(json_file)\n",
        "  with open(dictionary_storage_location+'Users_Watched_Movies.json') as json_file:\n",
        "      Users_Watched_Movies = json.load(json_file)\n",
        "  def def_value():\n",
        "      return \"Not Present\"\n",
        "        \n",
        "  # Defining the dict\n",
        "  iid_dict = defaultdict(int,iid_dict)\n",
        "  uid_dict = defaultdict(int,uid_dict)\n",
        "\n",
        "  #Defining inverted dictionaries\n",
        "  inv_uid = {v: k for k, v in uid_dict.items()}\n",
        "  inv_iid = {v: k for k, v in iid_dict.items()}\n",
        "\n",
        "\n",
        "  model_uid=str(uid_dict[og_user])\n",
        "  print(\"MODEL UID:\",model_uid,\"OG ID\",og_user)\n",
        "  all_movies_user_saw=Users_Watched_Movies[model_uid]\n",
        "\n",
        "  setA = set(list(iid_dict.values()))\n",
        "  setB = set(all_movies_user_saw)\n",
        "\n",
        "  # Removing movies which user has already seen\n",
        "  onlyInA = setA.difference(setB)\n",
        "  predictions=[]\n",
        "  for movie in onlyInA:\n",
        "    predictions.append(predict(algo,model_uid,movie)[3])\n",
        "\n",
        "  preds_for_a_user=dict(zip(onlyInA,predictions))\n",
        "  top20movieIDs = dict(sorted(preds_for_a_user.items(), key = itemgetter(1), reverse = True)[:20])\n",
        "  # print(top20movieIDs)\n",
        "  top20movieNames=[inv_iid[i] for i in list(top20movieIDs.keys())]\n",
        "  out_json={\"message\": \"OK\", \"recommendations\": top20movieNames }\n",
        "  return out_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYVuuI0ijU04"
      },
      "outputs": [],
      "source": [
        "# Code to get a model's performace, wrt : Avg. Training time and RMSE on a K-Folded Cross Validation Process\n",
        "# Assumption that a model has been trained earlier, however, this below process only uses the architecture and not the trained model. It will re-fit the data again.\n",
        "# Hence, Data Location is essential.\n",
        "# The purpose of this code is only model evaualtion for the sake of seperation of concerns.\n",
        "\n",
        "from surprise import Reader\n",
        "from surprise import NMF\n",
        "from surprise import SVDpp\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise.accuracy import rmse\n",
        "from surprise.model_selection import KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle \n",
        "import requests\n",
        "\n",
        "#Please update your desitination location if its different\n",
        "\n",
        "#Codes to store the model into pickle \n",
        "def store_model_into_pickle(algo,algo_name,dest_location=\"/content/drive/MyDrive/Collab Codes/MLIP/\"):\n",
        "  file1 = open(dest_location+algo_name+\".pickle\", \"wb\")\n",
        "  pickle.dump(algo, file1)\n",
        "  file1.close()\n",
        "  print(algo_name+\" Stored at/as :\"+dest_location+algo_name+\".pickle\")\n",
        "  return True\n",
        "\n",
        "#Codes to get the model from pickle \n",
        "def get_model_from_pickle(algo_name,file_location=\"/content/drive/MyDrive/Collab Codes/MLIP/\"):\n",
        "  file_to_read = open(file_location+algo_name+\".pickle\", \"rb\")\n",
        "  loaded_object = pickle.load(file_to_read)\n",
        "  file_to_read.close()\n",
        "  print(\"returned model object\")\n",
        "  return loaded_object\n",
        "\n",
        "\n",
        "\n",
        "def get_avg_throughputtime(data_location=\"/content/drive/MyDrive/Collab Codes/MLIP/preprocessed.csv\"):\n",
        "  df=pd.read_csv(data_location)\n",
        "  request_list=['http://128.2.205.106:8082/recommend/'+str(i) for i in np.unique(df.UserID.sample(500))]\n",
        "\n",
        "  times=[]\n",
        "  # Making a get request\n",
        "  for i in request_list:\n",
        "    response = requests.get(i)\n",
        "    times.append(response.elapsed.total_seconds())\n",
        "\n",
        "  print(\"AVG Throughput\",np.mean(times))\n",
        "  return np.mean(times)\n",
        "\n",
        "# An existing model architechture chan be passed to the below code, and the code will re-fit the model on the k-folded data and give the most realistic k-fold cross validation RMSE\n",
        "def evaluate_model(model_name=\"svdpp_model\",processed__test_data_file=\"/content/drive/MyDrive/Collab Codes/MLIP/RemappedData.csv\"):\n",
        "\n",
        "  algo=get_model_from_pickle(model_name)\n",
        "  Data_selected=pd.read_csv(processed__test_data_file)\n",
        "  reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "  # Loads Pandas dataframe\n",
        "  data = Dataset.load_from_df(Data_selected[[\"user\", \"item\", \"rating\"]], reader)\n",
        "\n",
        "  #KFold helps us to spit the dataset into n folds, this will help us seperate training and testing splits while calculating testing erros\n",
        "\n",
        "  kf = KFold(n_splits=4)\n",
        "  errors=[]\n",
        "  training_time=[]\n",
        "  for trainset, testset in kf.split(data):\n",
        "    start_time = time.time()\n",
        "    #Fitting\n",
        "    algo.fit(trainset)      \n",
        "    end_time=time.time()               \n",
        "    time_for_fitting=(time.time() - start_time)\n",
        "\n",
        "    # we are checking for test rmse only, and computing avg of all CV in the k splits\n",
        "    predictions = algo.test(testset)\n",
        "    #appending results to a list for future references\n",
        "    errors.append(rmse(predictions))\n",
        "    training_time.append(time_for_fitting)\n",
        "    \n",
        "  # This code only returns the avg RMSE error and avg training time for a k folded dataset\n",
        "  return np.mean(errors),np.mean(training_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvD8JKHqVDnF",
        "outputId": "305230cb-aa95-4c20-e561-f4e590347802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data.shape (435452, 4)\n",
            "Saved at:  /content/drive/MyDrive/Collab Codes/MLIP/preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "# FINAL SEQUENTIAL EXECUTION ONE TIME\n",
        "start_time = time.time()\n",
        "DataPreProcessing()\n",
        "end_time=time.time()\n",
        "time_for_dataProcessing=(time.time() - start_time)\n",
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Collab Codes/MLIP/preprocessed.csv\")\n",
        "sampled_df=df.sample(170000)\n",
        "sampled_df.to_csv(\"/content/drive/MyDrive/Collab Codes/MLIP/sampled_170kpreprocessed.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ_JM7GvadBs",
        "outputId": "8bfa83f7-75e8-4309-ed5d-9f2cdfb68b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.9557\n",
            "RMSE: 0.9478\n",
            "RMSE: 0.9551\n",
            "RMSE: 1.1407\n",
            "RMSE: 1.1437\n",
            "RMSE: 1.1408\n",
            "RMSE: 0.9604\n",
            "RMSE: 0.9575\n",
            "RMSE: 0.9591\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "make_Dictionaries(processed_data_file=\"/content/drive/MyDrive/Collab Codes/MLIP/sampled_20kpreprocessed.csv\")\n",
        "DataRemapping(processed_data_file=\"/content/drive/MyDrive/Collab Codes/MLIP/sampled_20kpreprocessed.csv\")\n",
        "end_time=time.time()\n",
        "time_for_dataReMapping=(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "svdpp_algo,avgerror_svdpp=train_svdpp()\n",
        "end_time=time.time()\n",
        "time_for_svdpp=(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "nmf_algo,avgerror_nmf=train_nmf()\n",
        "end_time=time.time()\n",
        "time_for_nmf=(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "svd_algo,avgerror_svd=train_SVD_wGridSearch()\n",
        "end_time=time.time()\n",
        "time_for_SVD=(time.time() - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQZC160WVOab",
        "outputId": "232b2420-fa18-46bc-9b2e-e0317d692996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nmf_model Stored at/as :/content/drive/MyDrive/Collab Codes/MLIP/nmf_model.pickle\n",
            "returned model object\n",
            "svdpp_model Stored at/as :/content/drive/MyDrive/Collab Codes/MLIP/svdpp_model.pickle\n",
            "returned model object\n",
            "svd_model Stored at/as :/content/drive/MyDrive/Collab Codes/MLIP/svd_model.pickle\n",
            "returned model object\n"
          ]
        }
      ],
      "source": [
        "# FINAL SEQUENTIAL EXECUTION ONE TIME\n",
        "store_model_into_pickle(nmf_algo,\"nmf_model\")\n",
        "nmf_algo=get_model_from_pickle(algo_name=\"nmf_model\")\n",
        "store_model_into_pickle(svdpp_algo,\"svdpp_model\")\n",
        "svdpp_algo=get_model_from_pickle(algo_name=\"svdpp_model\")\n",
        "store_model_into_pickle(svd_algo,\"svd_model\")\n",
        "svd_algo=get_model_from_pickle(algo_name=\"svd_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuUB-yMwl0nj",
        "outputId": "7e03b419-99a9-49a2-a33d-d4924b4385a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "returned model object\n",
            "RMSE: 0.9546\n",
            "RMSE: 0.9473\n",
            "RMSE: 0.9453\n",
            "RMSE: 0.9480\n",
            "returned model object\n",
            "RMSE: 1.1284\n",
            "RMSE: 1.1378\n",
            "RMSE: 1.1281\n",
            "RMSE: 1.1303\n",
            "returned model object\n",
            "RMSE: 0.9525\n",
            "RMSE: 0.9584\n",
            "RMSE: 0.9570\n",
            "RMSE: 0.9577\n"
          ]
        }
      ],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "avgerror_svdpp,training_time_svdpp=evaluate_model(\"svdpp_model\")\n",
        "end_time=time.time()\n",
        "time_for_svdpp=(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "avgerror_nmf,training_time_nmf=evaluate_model(\"nmf_model\")\n",
        "end_time=time.time()\n",
        "time_for_nmf=(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "avgerror_svd,training_time_svd=evaluate_model(\"svd_model\")\n",
        "end_time=time.time()\n",
        "time_for_SVD=(time.time() - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmuTqJpfoJUO",
        "outputId": "a6a914a4-a28b-4b91-ab6d-673f14f1dbc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "returned model object\n",
            "MODEL UID: 14202 OG ID 63233\n",
            "returned model object\n",
            "MODEL UID: 14202 OG ID 63233\n",
            "returned model object\n",
            "MODEL UID: 14202 OG ID 63233\n"
          ]
        }
      ],
      "source": [
        "#API RETURN , MANY TIMES ACCESS\n",
        "start_time = time.time()\n",
        "temp=recommend_top_20_modviesForUser(\"svd_model\",63233)\n",
        "end_time=time.time()\n",
        "time_for_SVD_pred=(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "temp=recommend_top_20_modviesForUser(\"svdpp_model\",63233)\n",
        "end_time=time.time()\n",
        "time_for_SVDPP_pred=(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "temp=recommend_top_20_modviesForUser(\"nmf_model\",63233)\n",
        "end_time=time.time()\n",
        "time_for_NMF_pred=(time.time() - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCQ8hZCQiJyT",
        "outputId": "7c2aa192-1991-421d-9510-59e078ccfb84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL AVG RMSE ERROR after 3 fold CV SVD: 0.9564021739184455\n",
            "MODEL AVG RMSE ERROR after 3 fold CV SVDPP: 0.9487898160307124\n",
            "MODEL AVG RMSE ERROR after 3 fold CV NMF: 1.1311381396938485\n",
            "\n",
            "(seconds) Time for Data Processing:  2.2956197261810303\n",
            "(seconds) Time for Data Remapping:  2.2296266555786133\n",
            "\n",
            "(seconds) Time for Model Training (SVD):  3.9703701734542847\n",
            "(seconds) Time for Model Training (SVDPP):  13.818799376487732\n",
            "(seconds) Time for Model Training (NMF):  12.65781307220459\n",
            "\n",
            "(seconds) Time for Model Prediction (SVD):  0.723773717880249\n",
            "(seconds) Time for Model Prediction (SVDPP):  0.6875138282775879\n",
            "(seconds) Time for Model Prediction (NMF):  0.5831031799316406\n",
            "\n",
            "Storage Size for Model Pickle (SVD) in MB:  47.571370124816895\n",
            "Storage Size for Model Pickle (SVDPP) in MB:  15.210856437683105\n",
            "Storage Size for Model Pickle (NMF) in MB:  11.146574020385742\n"
          ]
        }
      ],
      "source": [
        "import sys,os\n",
        "\n",
        "print(\"MODEL AVG RMSE ERROR after 3 fold CV SVD:\",avgerror_svd)\n",
        "print(\"MODEL AVG RMSE ERROR after 3 fold CV SVDPP:\",avgerror_svdpp)\n",
        "print(\"MODEL AVG RMSE ERROR after 3 fold CV NMF:\",avgerror_nmf)\n",
        "print()\n",
        "\n",
        "print(\"(seconds) Time for Data Processing: \",time_for_dataProcessing)\n",
        "print(\"(seconds) Time for Data Remapping: \",time_for_dataReMapping)\n",
        "print()\n",
        "print(\"(seconds) Time for Model Training (SVD): \",training_time_svd)\n",
        "print(\"(seconds) Time for Model Training (SVDPP): \",training_time_svdpp)\n",
        "print(\"(seconds) Time for Model Training (NMF): \",training_time_nmf)\n",
        "print()\n",
        "print(\"(seconds) Time for Model Prediction (SVD): \",time_for_SVD_pred)\n",
        "print(\"(seconds) Time for Model Prediction (SVDPP): \",time_for_SVDPP_pred)\n",
        "print(\"(seconds) Time for Model Prediction (NMF): \",time_for_NMF_pred)\n",
        "print()\n",
        "print(\"Storage Size for Model Pickle (SVD) in MB: \",(os.stat(\"/content/drive/MyDrive/Collab Codes/MLIP/svd_model.pickle\").st_size / (1024 * 1024)))\n",
        "print(\"Storage Size for Model Pickle (SVDPP) in MB: \",(os.stat(\"/content/drive/MyDrive/Collab Codes/MLIP/svdpp_model.pickle\").st_size / (1024 * 1024)))\n",
        "print(\"Storage Size for Model Pickle (NMF) in MB: \",(os.stat(\"/content/drive/MyDrive/Collab Codes/MLIP/nmf_model.pickle\").st_size / (1024 * 1024)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "l8hfSuzybBnn",
        "outputId": "802f3cc1-5261-4d92-f15d-36d58473d92b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ea9b037f-2d63-4132-8a5c-1addc3790f43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>UserID</th>\n",
              "      <th>MovieName</th>\n",
              "      <th>rating</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>367672</td>\n",
              "      <td>367733</td>\n",
              "      <td>158998</td>\n",
              "      <td>raiders+of+the+lost+ark+1981</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-09-08T13:11:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>376673</td>\n",
              "      <td>376734</td>\n",
              "      <td>195350</td>\n",
              "      <td>robin+hood+prince+of+thieves+1991</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-09-08T16:05:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44801</td>\n",
              "      <td>44808</td>\n",
              "      <td>92730</td>\n",
              "      <td>forrest+gump+1994</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-08-28T18:51:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34986</td>\n",
              "      <td>34991</td>\n",
              "      <td>137202</td>\n",
              "      <td>superbad+2007</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-08-14T05:25:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>273867</td>\n",
              "      <td>273910</td>\n",
              "      <td>67535</td>\n",
              "      <td>vanilla+sky+2001</td>\n",
              "      <td>3</td>\n",
              "      <td>2022-08-28T05:42:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149995</th>\n",
              "      <td>327488</td>\n",
              "      <td>327538</td>\n",
              "      <td>219017</td>\n",
              "      <td>back+to+the+future+1985</td>\n",
              "      <td>3</td>\n",
              "      <td>2022-08-14T20:03:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149996</th>\n",
              "      <td>393082</td>\n",
              "      <td>393146</td>\n",
              "      <td>144962</td>\n",
              "      <td>three+days+2008</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-09-08T19:22:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149997</th>\n",
              "      <td>101453</td>\n",
              "      <td>101467</td>\n",
              "      <td>120517</td>\n",
              "      <td>amores+perros+2000</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-09-02T00:41:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149998</th>\n",
              "      <td>175149</td>\n",
              "      <td>175176</td>\n",
              "      <td>215113</td>\n",
              "      <td>happy+gilmore+1996</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-08-30T20:36:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149999</th>\n",
              "      <td>322236</td>\n",
              "      <td>322286</td>\n",
              "      <td>60798</td>\n",
              "      <td>the+specialist+1994</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-09-02T00:22:30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea9b037f-2d63-4132-8a5c-1addc3790f43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea9b037f-2d63-4132-8a5c-1addc3790f43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea9b037f-2d63-4132-8a5c-1addc3790f43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Unnamed: 0  Unnamed: 0.1  UserID                          MovieName  \\\n",
              "0           367672        367733  158998       raiders+of+the+lost+ark+1981   \n",
              "1           376673        376734  195350  robin+hood+prince+of+thieves+1991   \n",
              "2            44801         44808   92730                  forrest+gump+1994   \n",
              "3            34986         34991  137202                      superbad+2007   \n",
              "4           273867        273910   67535                   vanilla+sky+2001   \n",
              "...            ...           ...     ...                                ...   \n",
              "149995      327488        327538  219017            back+to+the+future+1985   \n",
              "149996      393082        393146  144962                    three+days+2008   \n",
              "149997      101453        101467  120517                 amores+perros+2000   \n",
              "149998      175149        175176  215113                 happy+gilmore+1996   \n",
              "149999      322236        322286   60798                the+specialist+1994   \n",
              "\n",
              "        rating            Timestamp  \n",
              "0            5  2022-09-08T13:11:40  \n",
              "1            4  2022-09-08T16:05:52  \n",
              "2            5  2022-08-28T18:51:11  \n",
              "3            4  2022-08-14T05:25:37  \n",
              "4            3  2022-08-28T05:42:15  \n",
              "...        ...                  ...  \n",
              "149995       3  2022-08-14T20:03:54  \n",
              "149996       2  2022-09-08T19:22:59  \n",
              "149997       4  2022-09-02T00:41:08  \n",
              "149998       4  2022-08-30T20:36:06  \n",
              "149999       4  2022-09-02T00:22:30  \n",
              "\n",
              "[150000 rows x 6 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_df=pd.read_csv(\"/content/drive/MyDrive/Collab Codes/MLIP/sampled_20kpreprocessed.csv\")\n",
        "sampled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5j40SWMVFZE",
        "outputId": "e6800144-2581-4557-b9ea-e7e4c9a991dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "returned model object\n",
            "MODEL UID: 14202 OG ID 63233\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'message': 'OK',\n",
              " 'recommendations': ['the+shawshank+redemption+1994',\n",
              "  'the+dark+knight+rises+2012',\n",
              "  'the+lives+of+others+2006',\n",
              "  'the+godfather+1972',\n",
              "  'the+philadelphia+story+1940',\n",
              "  'rebecca+1940',\n",
              "  'the+usual+suspects+1995',\n",
              "  'm+1931',\n",
              "  'annie+hall+1977',\n",
              "  'double+indemnity+1944',\n",
              "  'pride++prejudice+2005',\n",
              "  'the+wrong+trousers+1993',\n",
              "  'secrets++lies+1996',\n",
              "  'rear+window+1954',\n",
              "  'snatch+2000',\n",
              "  'the+godfather+part+ii+1974',\n",
              "  'monty+python+and+the+holy+grail+1975',\n",
              "  'schindlers+list+1993',\n",
              "  'spirited+away+2001',\n",
              "  'one+flew+over+the+cuckoos+nest+1975']}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#API RETURN , MANY TIMES ACCESS\n",
        "recommend_top_20_modviesForUser(\"svd_model\",63233)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPfAj3-3klWR",
        "outputId": "a8618f71-59a6-415c-cdc9-7c3842687e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "returned model object\n",
            "MODEL UID: 17662 OG ID 78444\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'message': 'OK',\n",
              " 'recommendations': ['the+shawshank+redemption+1994',\n",
              "  'the+lives+of+others+2006',\n",
              "  'the+seventh+seal+1957',\n",
              "  'the+godfather+1972',\n",
              "  '8+1963',\n",
              "  'snatch+2000',\n",
              "  'the+philadelphia+story+1940',\n",
              "  'the+usual+suspects+1995',\n",
              "  'spirited+away+2001',\n",
              "  'annie+hall+1977',\n",
              "  'schindlers+list+1993',\n",
              "  'the+wrong+trousers+1993',\n",
              "  'the+graduate+1967',\n",
              "  'crumb+1994',\n",
              "  'one+flew+over+the+cuckoos+nest+1975',\n",
              "  'monty+python+and+the+holy+grail+1975',\n",
              "  '12+angry+men+1957',\n",
              "  'lone+star+1996',\n",
              "  'seven+samurai+1954',\n",
              "  'fight+club+1999']}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#API RETURN , MANY TIMES ACCESS\n",
        "recommend_top_20_modviesForUser(\"svd_model\",78444)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg52Nw0NVSp0",
        "outputId": "be9ef999-398b-4866-db5e-7efda8f60b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "returned model object\n",
            "MODEL UID: 14202 OG ID 63233\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'message': 'OK',\n",
              " 'recommendations': ['saving+face+2004',\n",
              "  'one+lucky+elephant+2011',\n",
              "  'bigger+than+life+1956',\n",
              "  'dragon+day+2013',\n",
              "  'what+a+girl+wants+2003',\n",
              "  'antonio+das+mortes+1969',\n",
              "  'the+secret+of+roan+inish+1994',\n",
              "  'thieves+1996',\n",
              "  'moonlight+murder+1936',\n",
              "  'cinderella+1950',\n",
              "  'harvie+krumpet+2003',\n",
              "  'cross+of+iron+1977',\n",
              "  'the+long+goodbye+1973',\n",
              "  'the+spongebob+movie+sponge+out+of+water+2015',\n",
              "  'shattered+glass+2003',\n",
              "  'cj7+2008',\n",
              "  'the+long+kiss+goodnight+1996',\n",
              "  'wonderland+1999',\n",
              "  'ratcatcher+1999',\n",
              "  'the+boondock+saints+ii+all+saints+day+2009']}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#API RETURN , MANY TIMES ACCESS\n",
        "recommend_top_20_modviesForUser(\"knn_model\",63233)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrGiwP_xWRdY",
        "outputId": "52b4e559-a626-4044-d010-6d2b0e6d3b5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "returned model object\n",
            "MODEL UID: 17662 OG ID 78444\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'message': 'OK',\n",
              " 'recommendations': ['primal+fear+1996',\n",
              "  'the+tao+of+steve+2000',\n",
              "  'one+lucky+elephant+2011',\n",
              "  'catlow+1971',\n",
              "  'mr.+warmth+the+don+rickles+project+2007',\n",
              "  'the+secret+life+of+bees+2008',\n",
              "  'vixen+1968',\n",
              "  'alice+in+wonderland+2010',\n",
              "  'selena+1997',\n",
              "  'ratcatcher+1999',\n",
              "  'it+might+get+loud+2009',\n",
              "  'north+1994',\n",
              "  'inside+deep+throat+2005',\n",
              "  'great+freedom+no.+7+1944',\n",
              "  '200+cigarettes+1999',\n",
              "  'the+champ+1979',\n",
              "  '12+angry+men+1997',\n",
              "  'bigger+than+life+1956',\n",
              "  'thieves+1996',\n",
              "  'altered+2006']}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#API RETURN , MANY TIMES ACCESS\n",
        "recommend_top_20_modviesForUser(\"knn_model\",78444)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qplKRUQzkrCL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
